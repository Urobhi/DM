{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPAA02G5- AddNoise.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T72qMULPorkS",
        "colab_type": "text"
      },
      "source": [
        "Este Notebook esta basado en TPAA02G5 - Dataset.ipynb, se lo modificó para agregar ruidos de distintas amplitudes al conjunto de prueba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GuY1LGgicap",
        "colab_type": "text"
      },
      "source": [
        "#Importación de datos, librerias y parámetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmk8Y-Y5KX75",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "5927d48f-efd9-46d9-c898-d100e23ec0e4"
      },
      "source": [
        "!wget http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz\n",
        "!mkdir speechcommands\n",
        "!tar -xf speech_commands_v0.01.tar.gz -C /content/speechcommands"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-12 15:00:11--  http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.124.128, 2607:f8b0:4001:c14::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.124.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1489096277 (1.4G) [application/gzip]\n",
            "Saving to: ‘speech_commands_v0.01.tar.gz’\n",
            "\n",
            "speech_commands_v0. 100%[===================>]   1.39G  99.8MB/s    in 20s     \n",
            "\n",
            "2020-07-12 15:00:31 (71.4 MB/s) - ‘speech_commands_v0.01.tar.gz’ saved [1489096277/1489096277]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP7u4IVZI6HH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "from librosa.display import specshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg8unCJl2mq5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "104241cd-5591-45a3-f7c5-078149ac91bf"
      },
      "source": [
        "working_directory = '/content/speechcommands'\n",
        "numbers = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1nXyfqZikad",
        "colab_type": "text"
      },
      "source": [
        "#Definición de funciones para sumar ruido y calcular features\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UoUOfzYKnzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_features_noise(filename,Amp,noisevector, n_mfcc=12,delta=True,deltadelta=True,energy=True, summary_fn = [np.mean, np.std], summary_names=['mean','std']):\n",
        "  \n",
        "  \n",
        "  #Abro el archivo y sumo el ruido\n",
        "  x, sr = librosa.core.load(filename,sr=None)\n",
        "  noise_starter = np.random.randint(0,noisevector.size-x.size) # Defino un random para usar una cantidad de valores,  Me aseguro de no pasarme\n",
        "  x = x + Amp * noisevector[noise_starter:noise_starter+x.size] \n",
        "  #Calculo MFCCs\n",
        "  features = librosa.feature.mfcc(x,sr=sr,n_mfcc=n_mfcc)\n",
        "  feat_names = ['mfcc_{}'.format(i) for i in range(n_mfcc)]\n",
        "  #Calculo energia:\n",
        "  if energy:\n",
        "    energy = librosa.feature.rmse(x)\n",
        "    features = np.concatenate([features,energy])\n",
        "    feat_names = feat_names + ['energy']\n",
        "  #Aplico media y desvio estandar por defecto\n",
        "  summary_features = np.concatenate([fn(features,axis=1) for fn in summary_fn])\n",
        "  \n",
        "  #Lo mismo con los delta\n",
        "  if delta:\n",
        "    deltafeatures = np.diff(features)\n",
        "    summary_features = np.concatenate([summary_features,np.concatenate([fn(deltafeatures,axis=1) for fn in summary_fn])])\n",
        "    d_names = ['d{}'.format(name) for name in feat_names]\n",
        "  else:\n",
        "    d_names = []\n",
        "\n",
        "  #Y con los delta de segundo orden\n",
        "  if deltadelta:\n",
        "    deltadeltafeatures = np.diff(features,n=2)\n",
        "    summary_features = np.concatenate([summary_features,np.concatenate([fn(deltadeltafeatures,axis=1) for fn in summary_fn])]) \n",
        "    dd_names = ['dd{}'.format(name) for name in feat_names]\n",
        "  else:\n",
        "    dd_names = []\n",
        "\n",
        "  feat_names = feat_names + d_names + dd_names\n",
        "  #feat_names = ['{}_{}'.format(feat,summary) for feat in feat_names for summary in summary_names]\n",
        "  feat_names = ['{}_{}'.format(name_i,summ_i) for summ_i in summary_names for name_i in feat_names]\n",
        "  return summary_features, feat_names  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHgpt_NXmcy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_features_whitenoise(filename,Amp, n_mfcc=12,delta=True,deltadelta=True,energy=True, summary_fn = [np.mean, np.std], summary_names=['mean','std']):\n",
        "  # Defino un random para usar una cantidad de valores\n",
        "  \n",
        "  #Abro el archivo y sumo el ruido\n",
        "  x, sr = librosa.core.load(filename,sr=None)\n",
        "  noise = np.random.normal(size=x.size)\n",
        "  x = x + Amp * noise * max(x)\n",
        "  #Calculo MFCCs\n",
        "  features = librosa.feature.mfcc(x,sr=sr,n_mfcc=n_mfcc)\n",
        "  feat_names = ['mfcc_{}'.format(i) for i in range(n_mfcc)]\n",
        "  #Calculo energia:\n",
        "  if energy:\n",
        "    energy = librosa.feature.rmse(x)\n",
        "    features = np.concatenate([features,energy])\n",
        "    feat_names = feat_names + ['energy']\n",
        "  #Aplico media y desvio estandar por defecto\n",
        "  summary_features = np.concatenate([fn(features,axis=1) for fn in summary_fn])\n",
        "  \n",
        "  #Lo mismo con los delta\n",
        "  if delta:\n",
        "    deltafeatures = np.diff(features)\n",
        "    summary_features = np.concatenate([summary_features,np.concatenate([fn(deltafeatures,axis=1) for fn in summary_fn])])\n",
        "    d_names = ['d{}'.format(name) for name in feat_names]\n",
        "  else:\n",
        "    d_names = []\n",
        "\n",
        "  #Y con los delta de segundo orden\n",
        "  if deltadelta:\n",
        "    deltadeltafeatures = np.diff(features,n=2)\n",
        "    summary_features = np.concatenate([summary_features,np.concatenate([fn(deltadeltafeatures,axis=1) for fn in summary_fn])]) \n",
        "    dd_names = ['dd{}'.format(name) for name in feat_names]\n",
        "  else:\n",
        "    dd_names = []\n",
        "\n",
        "  feat_names = feat_names + d_names + dd_names\n",
        "  #feat_names = ['{}_{}'.format(feat,summary) for feat in feat_names for summary in summary_names]\n",
        "  feat_names = ['{}_{}'.format(name_i,summ_i) for summ_i in summary_names for name_i in feat_names]\n",
        "  return summary_features, feat_names "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G3PNrUfiskx",
        "colab_type": "text"
      },
      "source": [
        "# Division en Entrenamiento, validación y testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDIUU1nSm4Yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fill_types(file_type, file, t, base_path = '/content/speechcommands'):\n",
        "    for line in file:\n",
        "        line = line.strip()\n",
        "        for number in numbers:\n",
        "            if line.startswith(number + '/'):\n",
        "                file_type[os.path.join(base_path, line)] = t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9Lzs-hd2F98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_type = {}\n",
        "\n",
        "with open('/content/speechcommands/testing_list.txt') as file:\n",
        "    fill_types(file_type, file, 'testing', base_path = working_directory)\n",
        "\n",
        "with open('/content/speechcommands/validation_list.txt') as file:\n",
        "    fill_types(file_type, file, 'validation', base_path = working_directory)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGMDDRUUnZbD",
        "colab_type": "text"
      },
      "source": [
        "# Generacion de datasets con distintas amplitudes y para distintos ruidos ambientales\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hjkc2ktIjTVA",
        "colab_type": "text"
      },
      "source": [
        "Generación de mfcc usando ruido blanco para el conjunto de prueba,guardando en la raiz de gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF0nK2b0k94B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_type_validation = {k: v for k, v in file_type.items() if v== 'testing'}  # Set de prueba\n",
        "\n",
        "amplitudes = np.linspace(0.01,0.1,10)\n",
        "csvname= 'Validation_gaussian.csv' \n",
        "for amplitude in amplitudes:\n",
        "  data = []\n",
        "  columns = []\n",
        "  csvname = 'A_' + str(amplitude) + '_whitenoise.csv'\n",
        "  for number in numbers:\n",
        "      for filepath in glob.glob(working_directory + '/' + number  + '/' + '/*.wav'):\n",
        "          if filepath in file_type_validation:\n",
        "            (feat, names) = calculate_features_whitenoise(filepath,amplitude)\n",
        "            t = file_type_validation[filepath] if filepath in file_type_validation else 'training'\n",
        "            data.append(np.append(feat, [number, filepath, t,amplitude, 'White']))\n",
        "            columns = names + ['target', 'filename', 'type', 'amplitude', 'ruido']\n",
        "  dataset = pd.DataFrame(data, columns = columns)\n",
        "  dataset.to_csv(os.path.join('/content/drive/My Drive/',csvname))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdWIaxj9kxP5",
        "colab_type": "text"
      },
      "source": [
        "Generación de mfcc usando ruidos ambientales para el conjunto de prueba, guardando en la raiz de gdrive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSUG__wcTR8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_type_validation = {k: v for k, v in file_type.items() if v== 'testing'}# Set de prueba\n",
        "noisepaths = glob.glob('Ruidos/*.wav')  # Subir cualquier archivo wav de ruido a la carpeta para poder usarlo\n",
        "\n",
        "amplitudes = np.linspace(1,10,10)\n",
        "for amplitude in amplitudes:\n",
        "  for noisepath in noisepaths:\n",
        "    csvname = 'A_' + str(amplitude) + '_' + os.path.split(noisepath)[1] + '.csv'\n",
        "    noise,sr = librosa.core.load(noisepath,sr=None)\n",
        "    data = []\n",
        "    columns = []\n",
        "    for number in numbers:\n",
        "        for filepath in glob.glob(working_directory + '/' + number  + '/' + '/*.wav'):\n",
        "            if filepath in file_type_validation:\n",
        "              (feat, names) = calculate_features_noise(filepath,amplitude, noise )\n",
        "              t = file_type_validation[filepath] if filepath in file_type_validation else 'training'\n",
        "              data.append(np.append(feat, [number, filepath, t, amplitude,os.path.split(noisepath)[1]]))\n",
        "              columns = names + ['target', 'filename', 'type','amplitude', 'ruido' ]\n",
        "    dataset = pd.DataFrame(data, columns = columns)\n",
        "    dataset.to_csv(os.path.join('/content/drive/My Drive/',csvname))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}