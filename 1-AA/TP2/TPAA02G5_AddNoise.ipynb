{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPAA02G5- AddNoise.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmk8Y-Y5KX75",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "646dcc9e-8d73-45a1-e3c9-9c4160eedd9a"
      },
      "source": [
        "!wget http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz\n",
        "!mkdir speechcommands\n",
        "!tar -xf speech_commands_v0.01.tar.gz -C /content/speechcommands"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-05 19:44:00--  http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 64.233.188.128, 2404:6800:4008:c06::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|64.233.188.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1489096277 (1.4G) [application/gzip]\n",
            "Saving to: ‘speech_commands_v0.01.tar.gz’\n",
            "\n",
            "speech_commands_v0. 100%[===================>]   1.39G   105MB/s    in 14s     \n",
            "\n",
            "2020-07-05 19:44:15 (99.8 MB/s) - ‘speech_commands_v0.01.tar.gz’ saved [1489096277/1489096277]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP7u4IVZI6HH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "from librosa.display import specshow"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg8unCJl2mq5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "240500ae-b1cd-4dc0-e052-1a8530297795"
      },
      "source": [
        "working_directory = '/content/speechcommands'\n",
        "numbers = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UoUOfzYKnzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_features_noise(filename,noisevector, n_mfcc=12,delta=True,deltadelta=True,energy=True, summary_fn = [np.mean, np.std], summary_names=['mean','std']):\n",
        "  \n",
        "  \n",
        "  #Abro el archivo y sumo el ruido\n",
        "  x, sr = librosa.core.load(filename,sr=None)\n",
        "  noise_starter = np.random.randint(0,noisevector.size-x.size) # Defino un random para usar una cantidad de valores,  Me aseguro de no pasarme\n",
        "  x = x + noisevector[noise_starter:noise_starter+x.size]\n",
        "  #Calculo MFCCs\n",
        "  features = librosa.feature.mfcc(x,sr=sr,n_mfcc=n_mfcc)\n",
        "  feat_names = ['mfcc_{}'.format(i) for i in range(n_mfcc)]\n",
        "  #Calculo energia:\n",
        "  if energy:\n",
        "    energy = librosa.feature.rmse(x)\n",
        "    features = np.concatenate([features,energy])\n",
        "    feat_names = feat_names + ['energy']\n",
        "  #Aplico media y desvio estandar por defecto\n",
        "  summary_features = np.concatenate([fn(features,axis=1) for fn in summary_fn])\n",
        "  \n",
        "  #Lo mismo con los delta\n",
        "  if delta:\n",
        "    deltafeatures = np.diff(features)\n",
        "    summary_features = np.concatenate([summary_features,np.concatenate([fn(deltafeatures,axis=1) for fn in summary_fn])])\n",
        "    d_names = ['d{}'.format(name) for name in feat_names]\n",
        "  else:\n",
        "    d_names = []\n",
        "\n",
        "  #Y con los delta de segundo orden\n",
        "  if deltadelta:\n",
        "    deltadeltafeatures = np.diff(features,n=2)\n",
        "    summary_features = np.concatenate([summary_features,np.concatenate([fn(deltadeltafeatures,axis=1) for fn in summary_fn])]) \n",
        "    dd_names = ['dd{}'.format(name) for name in feat_names]\n",
        "  else:\n",
        "    dd_names = []\n",
        "\n",
        "  feat_names = feat_names + d_names + dd_names\n",
        "  #feat_names = ['{}_{}'.format(feat,summary) for feat in feat_names for summary in summary_names]\n",
        "  feat_names = ['{}_{}'.format(name_i,summ_i) for summ_i in summary_names for name_i in feat_names]\n",
        "  return summary_features, feat_names  "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHgpt_NXmcy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_features_whitenoise(filename, n_mfcc=12,delta=True,deltadelta=True,energy=True, summary_fn = [np.mean, np.std], summary_names=['mean','std']):\n",
        "  # Defino un random para usar una cantidad de valores\n",
        "  \n",
        "  #Abro el archivo y sumo el ruido\n",
        "  x, sr = librosa.core.load(filename,sr=None)\n",
        "  noise = np.random.normal(size=x.size)\n",
        "  x = x + noise\n",
        "  #Calculo MFCCs\n",
        "  features = librosa.feature.mfcc(x,sr=sr,n_mfcc=n_mfcc)\n",
        "  feat_names = ['mfcc_{}'.format(i) for i in range(n_mfcc)]\n",
        "  #Calculo energia:\n",
        "  if energy:\n",
        "    energy = librosa.feature.rmse(x)\n",
        "    features = np.concatenate([features,energy])\n",
        "    feat_names = feat_names + ['energy']\n",
        "  #Aplico media y desvio estandar por defecto\n",
        "  summary_features = np.concatenate([fn(features,axis=1) for fn in summary_fn])\n",
        "  \n",
        "  #Lo mismo con los delta\n",
        "  if delta:\n",
        "    deltafeatures = np.diff(features)\n",
        "    summary_features = np.concatenate([summary_features,np.concatenate([fn(deltafeatures,axis=1) for fn in summary_fn])])\n",
        "    d_names = ['d{}'.format(name) for name in feat_names]\n",
        "  else:\n",
        "    d_names = []\n",
        "\n",
        "  #Y con los delta de segundo orden\n",
        "  if deltadelta:\n",
        "    deltadeltafeatures = np.diff(features,n=2)\n",
        "    summary_features = np.concatenate([summary_features,np.concatenate([fn(deltadeltafeatures,axis=1) for fn in summary_fn])]) \n",
        "    dd_names = ['dd{}'.format(name) for name in feat_names]\n",
        "  else:\n",
        "    dd_names = []\n",
        "\n",
        "  feat_names = feat_names + d_names + dd_names\n",
        "  #feat_names = ['{}_{}'.format(feat,summary) for feat in feat_names for summary in summary_names]\n",
        "  feat_names = ['{}_{}'.format(name_i,summ_i) for summ_i in summary_names for name_i in feat_names]\n",
        "  return summary_features, feat_names "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDIUU1nSm4Yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fill_types(file_type, file, t, base_path = '/content/speechcommands'):\n",
        "    for line in file:\n",
        "        line = line.strip()\n",
        "        for number in numbers:\n",
        "            if line.startswith(number + '/'):\n",
        "                file_type[os.path.join(base_path, line)] = t"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9Lzs-hd2F98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_type = {}\n",
        "\n",
        "with open('/content/speechcommands/testing_list.txt') as file:\n",
        "    fill_types(file_type, file, 'testing', base_path = working_directory)\n",
        "\n",
        "with open('/content/speechcommands/validation_list.txt') as file:\n",
        "    fill_types(file_type, file, 'validation', base_path = working_directory)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGMDDRUUnZbD",
        "colab_type": "text"
      },
      "source": [
        "Este bloque le suma ruido blanco al conkunto de validación y lo guarda en gdrive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF0nK2b0k94B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_type_validation = {k: v for k, v in file_type.items() if v== 'validation'}\n",
        "\n",
        "csvname= 'Validation_gaussian.csv'\n",
        "data = []\n",
        "columns = []\n",
        "for number in numbers:\n",
        "    for filepath in glob.glob(working_directory + '/' + number  + '/' + '/*.wav'):\n",
        "        if filepath in file_type_validation:\n",
        "          (feat, names) = calculate_features_whitenoise(filepath)\n",
        "          t = file_type_validation[filepath] if filepath in file_type_validation else 'training'\n",
        "          data.append(np.append(feat, [number, filepath, t]))\n",
        "          columns = names + ['target', 'filename', 'type']\n",
        "\n",
        "dataset = pd.DataFrame(data, columns = columns)\n",
        "dataset.to_csv(os.path.join('/content/drive/My Drive/',csvname))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdWIaxj9kxP5",
        "colab_type": "text"
      },
      "source": [
        "Generación de mfcc usando ruidos ambientales para el conjunto de validación, guardando en la raiz de gdrive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSUG__wcTR8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_type_validation = {k: v for k, v in file_type.items() if v== 'validation'}\n",
        "noisepaths = glob.glob('Ruidos/*.wav')  # Subir cualquier archivo wav de ruido a la carpeta para poder usarlo\n",
        "\n",
        "for noisepath in noisepaths:\n",
        "  csvname = os.path.split(noisepath)[1] + '.csv'\n",
        "  noise,sr = librosa.core.load(noisepath,sr=None)\n",
        "  data = []\n",
        "  columns = []\n",
        "  for number in numbers:\n",
        "      for filepath in glob.glob(working_directory + '/' + number  + '/' + '/*.wav'):\n",
        "          if filepath in file_type_validation:\n",
        "            (feat, names) = calculate_features(filepath, noise)\n",
        "            t = file_type_validation[filepath] if filepath in file_type_validation else 'training'\n",
        "            data.append(np.append(feat, [number, filepath, t]))\n",
        "            columns = names + ['target', 'filename', 'type']\n",
        "\n",
        "  dataset = pd.DataFrame(data, columns = columns)\n",
        "  dataset.to_csv(os.path.join('/content/drive/My Drive/',csvname))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}